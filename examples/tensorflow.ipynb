{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConfigState example with training a model using Tensorflow\n",
    "\n",
    "This notebook presents an example of how the config-state library can be used to design a machine learning experiment that consists in training an image classification model. We show how the different components, the dataset, the model and the optimizer can be configured and modified through a config file without requiring to write code. We also show how the experiment can be saved at regular intervals and be resumed in case of interruption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Requirements\n",
    "\n",
    "The packages `tensorflow` and `tensorflow-datasets` are required for this example:\n",
    "```\n",
    "pip install tensorflow\n",
    "pip install tensorflow-datasets\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `MLExperiment` class\n",
    "\n",
    "The `MLExperiment` class is a `ConfigState` subclass that defines the experiment consisting of training a machine learning model for image classification. It is composed of nested `ConfigState` objects that represent the different components such as `Dataset`, `Model` and `Optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # reduce tensorflow's verbosity\n",
    "\n",
    "from examples.tensorflow.experiment import MLExperiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring a `MLExperiment` experiment\n",
    "The directory `examples/tensorflow/configs` contains examples of configuration files that can be used to configure an experiment. Let's load one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "config = yaml.load(open(\"tensorflow/configs/mlp.yml\", 'r'), Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An experiment can be instantiated using this configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = MLExperiment(config)\n",
    "\n",
    "print(experiment.config_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start training the model for a given number of epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.run(epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and restoring an experiment\n",
    "\n",
    "The current experiment's state can been saved into file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_state import Serializer\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "# create a temporary directory\n",
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "# file that will store the experiment\n",
    "file_path = Path(temp_dir.name) / 'exp.save'\n",
    "\n",
    "# save the experiment using the Pickle serializer\n",
    "Serializer({'class': 'Pickle'}).save(experiment, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The experiment can be restored and resumed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Serializer({'class': 'Pickle'}).load(file_path)\n",
    "\n",
    "experiment.run(epochs=2)\n",
    "\n",
    "temp_dir.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring a new experiment\n",
    "\n",
    "We can customize the config dictionary to design a new experiment with a different datatet, model or optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['dataset'] = {\n",
    "    'name': 'cifar10' # https://www.tensorflow.org/datasets/catalog/overview#image_classification\n",
    "}\n",
    "config['model'] = {\n",
    "    'class': 'CNN',\n",
    "    'structure': [32, 'max', 64, 'max', 64]\n",
    "}\n",
    "config['optimizer'] = {\n",
    "    'class': 'Adam',\n",
    "    'learning_rate': 0.001\n",
    "}\n",
    "\n",
    "experiment = MLExperiment(config)\n",
    "\n",
    "print(experiment.config_summary())\n",
    "\n",
    "experiment.run(epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConfigState objects composability\n",
    "\n",
    "`ConfigState` is convenient for compositing objects. For instance we can nest a `Model` into another `Ensembler` model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = {\n",
    "    'class': 'CNN',\n",
    "    'structure': [32, 'max', 64, 'max', 64]\n",
    "}\n",
    "\n",
    "config['model'] = {\n",
    "    'class': 'Ensembler',\n",
    "    'model': cnn_model,\n",
    "    'ensemble_size': 4\n",
    "}\n",
    "\n",
    "config['dataset'] = {\n",
    "    'name': 'cifar10',\n",
    "    'batch_size': 128 # We augment the batch_size so that each ensembled models train on batches of 32 elements\n",
    "}\n",
    "\n",
    "experiment = MLExperiment(config)\n",
    "\n",
    "print(experiment.config_summary())\n",
    "\n",
    "print(experiment.model.keras_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.run(epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `Ensembler` is itself a `Model`, we can compose it into another `Ensemble` such that we can define models that are ensemble of ensemble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = {\n",
    "    'class': 'CNN',\n",
    "    'structure': [32, 'max', 64, 'max', 64]\n",
    "}\n",
    "\n",
    "ensemble = {\n",
    "    'class': 'Ensembler',\n",
    "    'model': cnn_model,\n",
    "    'ensemble_size': 4\n",
    "}\n",
    "\n",
    "config['model'] = {\n",
    "    'class': 'Ensembler',\n",
    "    'model': ensemble,\n",
    "    'ensemble_size': 4\n",
    "}\n",
    "\n",
    "config['dataset'] = {\n",
    "    'name': 'cifar10',\n",
    "    'batch_size': 512\n",
    "}\n",
    "\n",
    "experiment = MLExperiment(config)\n",
    "\n",
    "# ensemble_ensemble_exp.model.model.output_units\n",
    "print(experiment.config_summary())\n",
    "\n",
    "print(experiment.model.keras_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.run(epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}